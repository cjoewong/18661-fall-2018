<head>
    <meta charset="utf-8">
<title> CS260 ML Algorithms </title>
<meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="shortcut icon" href="../../docs-assets/ico/favicon.png">


    <!-- Bootstrap core CSS -->
    <link href="bootstrap.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="fall2018.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->
</head>

<body>
    <div class="container">
	 <div class="panel-footer clearfix">
        <div class="pull-left">
        
            <h1>18-461/18-661: Intro to ML for Engineers</h1>
            <p class="lead">Instructors:</p><p><a href=https://www.andrew.cmu.edu/user/cjoewong/ target="_blank">Prof. Carlee Joe-Wong</a> (SV)<br /><a href="http://users.ece.cmu.edu/~smithv/" target="_blank">Prof. Virginia Smith</a> (Pitt)</p>
            <p class="lead">Lecture:</p>
            <p>SV: Tues/Thurs 9:00am-10:20am PT, B23 109/110 
            <br />Pitt: Tues/Thurs 12:00pm-1:20pm ET, HH 1107</p>
            <p class="lead">Discussion:</p>
            <p>SV: Fri 2:30pm-3:50pm PT, B23 211
            <br />Pitt: Fri 12:00pm-1:20pm, SH 125</p>
            </div>
        </div>

        <div class="main">
        <br>
        <h3>Course Overview</h3>
        <p class="p1">This course provides an introduction to machine learning and statistical pattern recognition. We will cover approaches for supervised learning (linear models, kernel methods, decision trees, neural networks) and unsupervised learning (clustering, dimensionality reduction), as well as theoretical foundations of machine learning (learning theory, optimization). Evaluation will consist of mathematical problem sets and programming projects covering a variety of real-world applications.
        </p>

        <h3>Prerequisites</h3>
        <p>This course is intended for graduate students and qualified undergraduate students with a strong mathematical and programming background. Undergraduate level training or coursework in algorithms, linear
        algebra, calculus, probability, and statistics is suggested. A background in programming will also be necessary for the problem sets; students are expected to be familiar with python or learn it during the course. At CMU, this course is most similar to MLD's 10-601 or 10-701, though this course is meant specifically for students in engineering.</p>
    
        <h3>Textbooks</h3>
        There will be no required textbooks, though we suggest the
        following to help you to study:
        <ul>
          <li><i>Machine Learning: A Probabilistic Perspective</i> by Kevin Murphy.
          <li><i>Elements of Statistical Learning</i> by Trevor Hastie, Robert
          Tibshirani and Jerome Friedman (<a
            href="http://statweb.stanford.edu/~tibs/ElemStatLearn/"
            target="_blank">freely available online</a>). 
        </ul>
        We will provide suggested readings from these books in the schedule 
        below, using the acronyms MLAPA and ESL.

        <h3>Piazza</h3>
        <p> We will use Piazza for class discussions. Please go to <a href=http://piazza.com/ucla/spring2017/cs260 target="_blank" >this Piazza website</a> to join the course forum (note: you must use a ucla.edu email account to join the forum). We strongly encourage students to post on this forum rather than emailing the course staff directly (this will be more efficient for both students and staff). Students should use Piazza to: 
        <ul>
          <li>Ask clarifying questions about the course material.</li>
          <li>Share useful resources with classmates (so long as they do not
          contain homework solutions).</li>
          <li>Look for students to form study groups.</li>
          <li>Answer questions posted by other students to solidify your own
          understanding of the material.</li>
        </ul>
        The course Academic Integrity Policy must be followed on the message boards at all times. <b>Do not post or request homework solutions!</b> Also, please be polite.

        <h3>Staff Contact Info</h3>
        <p class="lead">TAs:</p><p>Gaun-Lin Chao (SV)<br />Madhumitha Harishankar (SV)<br />Michael Weber (SV)<br />Haewon Jeong (Pitt)<br />Joao Saude (Pitt)<br />Rohan Varma (Pitt)</p>

        <h3>Academic Integrity Policy</h3>
        Group studying and collaborating on problem sets are encouraged, as
        working together is a great way to understand new material.  Students
        are free to discuss the homework problems with anyone under the
        following conditions:
        <ul>
          <li>Students must write their own solutions and understand the
          solutions that they wrote down.</li>
          <li>Students must list the names of their collaborators (i.e., anyone
          with whom the assignment was discussed).</li>
          <li>Students may not use old solution sets from other classes under any circumstances, unless the instructor grants
          special permission.</li>
        </ul>
        
        Students are encouraged to read CMU's <a
          href=https://www.cmu.edu/policies/
          target="_blank"> Policy on Cheating and Plagiarism</a>.

        <h3>Grading Policy</h3>
        <p> Grades will be based on the following components: 
        <ul>
          <li> <b>Problem Sets (30%)</b>: There will be 6 problem sets. Each
          each problem set will have equal weight.
          <ul>
            <li> Problem sets are due at the beginning of class on the due
            date. <b>Late submissions will not be accepted</b>.
            <li> Students can drop their lowest grade (i.e., only the top 5
            grades will count). 
            <li> All solutions must be typed (preferably using LaTeX) and
            printed out. Solutions that are not typed will be penalized 50%;
            unreadable answers will not be graded.              
            <li> Solutions will be graded on both correctness and clarity. If
            you cannot solve a problem completely, you will get more partial
            credit by identifying the gaps in your argument than by 
            attempting to cover them up. 
          <li> For some assignments, it might be the case that only a subset of
          the problems will be graded in detail. Students may or may not be
          told which problems will be graded in advance. 
          </ul>
          <li> <b>Midterm (30%), Final (40%)</b>: These in-person exams will cover material
          from the lectures and the problem sets.
        </ul>

        <b>Gradescope:</b> We will use Gradescope to collect PDF submissions of each problem set. Upon uploading your PDF, Gradescope will ask you to identify which page(s) contains your solution for each problem – this is a great way to double check that you haven’t left anything out. The course staff will manually grade your submission, and you’ll receive feedback explaining your final marks.<br /><br />

        <b>Regrade Requests:</b> If you believe an error was made during grading, you’ll be able to submit a regrade request on Gradescope. <i>For each homework, regrade requests will be open for only 1 week after the grades have been published.</i> This is to encourage you to check the feedback you’ve received early!

        <h3>Using LaTeX</h3>
        <p> Students are strongly encouraged to use LaTeX.  LaTeX makes it
        simple to typeset mathematical equations, and is extremely useful for
        graduate students to know. Most of the academic papers you read were
        written with LaTeX, and probably most of the textbooks too. <a
          href=http://www.ctan.org/tex-archive/info/lshort/english/lshort.pdf
          target="_blank">Here</a> is an excellent LaTeX tutorial and <a
          href=http://latex-project.org/ftp.html target="_blank">here</a> are
        instructions for installing LaTeX on your machine.
        </p>

        <h3>Acknowledgments</h3>
        <p> This course is based in part on material developed by <a href=http://www-bcf.usc.edu/~feisha/ target="_blank">Fei Sha</a>, <a href="https://www.cs.cmu.edu/~atalwalk/" target="_blank">Ameet Talwalkar</a>, <a href="http://www.cs.cmu.edu/~mgormley/">Matt Gormley</a>, and <a href="https://homes.cs.washington.edu/~ebfox/">Emily Fox</a>. We also thank Anit Sahu and Joao Saude for their help with course development.
        <hr>


        <h3>Syllabus (Subject to Change)</h3>
        <div class="bs-example">
            <table class="table">
                <thead>
                    <tr>
                        <th>Week</th>
                        <th>Topics</th>
                        <!--<th>Reading</th>
                        <th>HW</th>-->
                    </tr>
                </thead>
                <tbody>
                    <tr class="active">
                        <td>0</td>
                        <td>
                        Intro to: Intro to ML
                        </td>
                    </tr>
                    <tr class="success">
                        <td>1</td>
                        <td>
                        Math Bootcamp: Linear Algebra, Probability, Calculus, Basics of Learning Theory and Optimization
                        </td>
                    </tr>
                    <tr class="active">
                        <td>2-4</td>
                        <td>Supervised Learning, Part I: K-nearest Neighbors, Naive Bayes, Decision Trees, Linear Regression, Logistic Regression
                        </td>
                    </tr>
                    <tr class="success">
                        <td>5-6</td>
                        <td>
                        Foundations: Optimization, Learning Theory, Overfitting, Bias/variance Tradeoff, Evaluation 
                        </td>
                    </tr>
                    <tr class="active">
                        <td>7-8
                        </td>
                        <td>
                        Supervised Learning, Part II: Kernel Methods, Boosting, Neural Networks
                        </td>
                    </tr>
                    <tr class="success">
                        <td>9-10</td>
                        <td>Unsupervised Learning: PCA, Clustering, EM
                        </td>
                    </tr>
                    <tr class="active">
                        <td>11+</td>
                        <td>
                        Additional Topics: HMMs, Graphical Models, Large-scale Machine Learning, Reinforcement Learning, Online Learning, Applications, ...
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>
        </div>

        <hr>
    </div>
    <!-- /container -->
 

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://code.jquery.com/jquery-1.10.2.min.js"></script>
    <script src="bootstrap/js/bootstrap.min.js"></script>


</body>
